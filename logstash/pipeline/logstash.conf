input {
	file {
	  max_open_files => 10
		mode => "read"
		path => ["/client_data/cluster-logs/**/system.log.*"]
		start_position => "beginning"
		file_completed_action => "log"
		file_completed_log_path => "/client_data/logstash-completed.log"
		codec => multiline {
			patterns_dir => ["/usr/share/logstash/config/patterns"]
			pattern => "%{CASS_DEFAULT}"
			negate => true
			what => "previous"
		}
	}
}

## Add your filters / logstash plugins configuration here

filter {
	grok {
		patterns_dir => ["/usr/share/logstash/config/patterns"]
    break_on_match => true
		match => { "message" => ["%{CASS_DEFAULT}"] }
		overwrite => [ "message", "@timestamp", "level", "process", "java_file"]
		add_tag => [ "cass_default" ]
  }

  if [fields][timezone] == "pst" {
      ## date is PST just parse it correctly
      date {
          locale => "en"
          match => ["timestamp", "YYYY-MM-dd HH:mm:ss,SSS"] # 2016-08-16 04:13:05,063
          timezone => "America/Los_Angeles"
          target => "@timestamp"
          #remove_field => "timestamp"
          # add_field => { "debug" => "tsMatched"}
     }
  } else if [fields][timezone] == "est" {
      ## date is EST
      date {
          locale => "en"
          match => ["timestamp", "YYYY-MM-dd HH:mm:ss,SSS"] # 2016-08-16 04:13:05,063
          timezone => "America/New_York"
          target => "@timestamp"
          #remove_field => "timestamp"
          # add_field => { "debug" => "tsMatched"}
     }
  } else {
      ## date is UTC just parse it correctly
      date {
          locale => "en"
          match => ["timestamp", "YYYY-MM-dd HH:mm:ss,SSS"] # 2016-08-16 04:13:05,063
          timezone => "Etc/UTC"
          target => "@timestamp"
          #remove_field => "timestamp"
          # add_field => { "debug" => "tsMatched"}
      }
  }

  mutate {
      convert => {
          "line_number" => "integer"
          "threadId" => "integer"
          "bytes_in" => "integer"
          "bytes_out" => "integer"
          "time_ms" => "integer"
          "bytes_onheap" => "integer"
          "bytes_offheap" => "integer"
          "commitlog_pos" => "integer"
          "eden_orig_bytes" => "integer"
          "eden_new_bytes" => "integer"
          "oldgen_orig_bytes" => "integer"
          "oldgen_new_bytes" => "integer"
          "survivor_new_bytes" => "integer"
          "survivor_orig_bytes" => "integer"
          "commitlog_segid" => "integer"
          "ops" => "integer"
          "pkeys_in" => "integer"
          "pkeys_out" => "integer"
          "percent_of_orig" => "integer"
          "cache_size" => "integer"
          "cache_used" => "integer"

          "threads_active" => "integer"
          "threads_pending" => "integer"
          "threads_blocked" => "integer"
          "threads_completed" => "integer"
          "threads_all_time_blocked" => "integer"

          "size_kb" => "float"
          "size_mb" => "float"
          "total_onheap" => "float"
          "total_offheap" => "float"
          "live_onheap" => "float"
          "live_offheap" => "float"
          "flushing_onheap" => "float"
          "flushing_offheap" => "float"
          "this_onheap" => "float"
          "this_offheap" => "float"
          "percent_onheap" => "float"
          "percent_offheap" => "float"
          "speed_mb" => "float"
       }
  }

  if [msg] {
      mutate {
          replace => [ "message", "%{msg}" ]
          remove_field => "msg"
      }
  }
}


output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		index => "logstash"
	}
	stdout {
		codec => rubydebug
	}
}
